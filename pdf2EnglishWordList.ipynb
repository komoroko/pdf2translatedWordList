{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pdfの英語文献から，出現頻度順の日訳英単語リストを作成するプログラム\n",
    "## INPUT : PDF 英語文献     \n",
    "## OUTPUT : CSV 翻訳 word list\n",
    "\n",
    "### 品詞の略については以下サイトを参照\n",
    "[Qiita](https://qiita.com/m__k/items/ffd3b7774f2fde1083fa \"NLTKの使い方をいろいろ調べてみた\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初期設定\n",
    "#### 最初の一回のみ，実行する．その後はコメントアウトしてよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用するライブラリのインストール\n",
    "# !pip install PyPDF2\n",
    "# !pip install nltk\n",
    "# !pip install deep_translator\n",
    "# !pip install tqdm\n",
    "\n",
    "# # nltkライブラリの事前ダウンロードファイル\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT: pdf_file に 読み込むパスを記述！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf 読み込み，textに変換．\n",
    "pdf_file = \"../../../RNA Viral Community in Human Feces.pdf\"\n",
    "with open(pdf_file, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfFileReader(f)\n",
    "    num_page = reader.getNumPages()\n",
    "    pages = []\n",
    "    for i in range(num_page):\n",
    "        pages.append(reader.getPage(i).extractText())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の整理: 単語群をもっと整えたい場合は，以下を編集するとよいかも\n",
    "### ほしい品詞なども設定できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "word_lists = []\n",
    "for i in range(num_page):\n",
    "    word_list = nltk.word_tokenize(pages[i])\n",
    "    word_lists.extend(word_list)\n",
    "\n",
    "# いらない単語を削除\n",
    "removed_word_list = []\n",
    "for word in word_lists:\n",
    "    if word.isalpha(): # アルファベットのみ使用\n",
    "        if len(word) > 1: # 1文字より大きい文字列のみ使用\n",
    "            removed_word_list.append(word)\n",
    "        \n",
    "        \n",
    "word_dict = {} # 重複回数をカウント\n",
    "for word in removed_word_list:\n",
    "    if not word in word_dict:\n",
    "        word_dict[word] = 1\n",
    "    else:\n",
    "        word_dict[word] += 1\n",
    "                \n",
    "\n",
    "sorted_dict = sorted(word_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "# 品詞の取得\n",
    "pos = nltk.pos_tag([pair[0] for pair in sorted_dict])\n",
    "\n",
    "print(len(pos))\n",
    "# 欲しい品詞のポジションを取得\n",
    "p = []\n",
    "for i, pair in enumerate(pos):\n",
    "    po = pair[1]\n",
    "    if any(x in po for x in [\"FW\", \"JJ\", \"LS\", \"MD\", \"NN\", \"RB\", \"RP\", \"VB\"]):\n",
    "        p.append(i)\n",
    "\n",
    "sorted_dict = np.array(sorted_dict)[p]\n",
    "pos = np.array(pos)[p]\n",
    "\n",
    "print(len(p))\n",
    "print(sorted_dict.shape)\n",
    "print(pos.shape)\n",
    "print((pos))\n",
    "print(sorted_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英日訳 1秒間隔で英日訳を取得\n",
    "- 単語数が少ない場合は，sleepを消してもよい．\n",
    "- 単語数が多く，sleepが短いと，接続がキャンセルされる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "\n",
    "translator = GoogleTranslator(sourse='en', target='ja')\n",
    "\n",
    "engs = []\n",
    "for i, word in tqdm(enumerate(sorted_dict), total=len(sorted_dict)):\n",
    "    translated = translator.translate(word[0])\n",
    "    engs.append(translated)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(sorted_dict[i][1], sorted_dict[i][0], pos[i][0], pos[i][1], translated))\n",
    "    sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要な配列をマージしておく "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts = [i[1] for i in sorted_dict]\n",
    "words = [i[0] for i in sorted_dict]\n",
    "poss = [i[1] for i in pos]\n",
    "\n",
    "result_df = pd.DataFrame(list(zip(counts, words, poss, engs)), columns=[\"出現回数\", \"英語\", \"品詞\", \"日訳\"]) \n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 翻訳前と翻訳後が同じであるものは削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.shape)\n",
    "\n",
    "result_df = result_df[~(result_df[\"英語\"]==result_df[\"日訳\"])]\n",
    "\n",
    "print(result_df.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT: save_fileに保存先パスを記述！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_file = os.path.splitext(pdf_file)[0] + \"_word_list\" + \".csv\"\n",
    "\n",
    "result_df.to_csv(save_file, encoding='utf-8-sig', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7abbde3a9bb075262fb4636cf59a3b2cb3f1b0a90ad9505cc4035096a888333e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
