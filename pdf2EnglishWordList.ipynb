{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pdfの英語文献から，出現頻度順の日訳英単語リストを作成するプログラム\n",
    "## INPUT : PDF 英語文献     \n",
    "## OUTPUT : CSV 翻訳 word list\n",
    "\n",
    "### 品詞の略については以下サイトを参照\n",
    "[Qiita](https://qiita.com/m__k/items/ffd3b7774f2fde1083fa \"NLTKの使い方をいろいろ調べてみた\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初期設定\n",
    "#### 最初の一回のみ，実行する．その後はコメントアウトしてよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用するライブラリのインストール\n",
    "# !pip install PyPDF2\n",
    "# !pip install nltk\n",
    "# !pip install deep_translator\n",
    "# !pip install tqdm\n",
    "\n",
    "# # nltkライブラリの事前ダウンロードファイル\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT: pdf_file に 読み込むパスを記述！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf 読み込み，textに変換．\n",
    "pdf_file = \"../RNA Viral Community in Human Feces.pdf\"\n",
    "with open(pdf_file, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfFileReader(f)\n",
    "    num_page = reader.getNumPages()\n",
    "    pages = []\n",
    "    for i in range(num_page):\n",
    "        pages.append(reader.getPage(i).extractText())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の整理: 単語群をもっと整えたい場合は，以下を編集するとよいかも\n",
    "### ほしい品詞なども設定できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "word_lists = []\n",
    "for i in range(num_page):\n",
    "    word_list = nltk.word_tokenize(pages[i])\n",
    "    word_lists.extend(word_list)\n",
    "\n",
    "# いらない単語を削除\n",
    "removed_word_list = []\n",
    "for word in word_lists:\n",
    "    if word.isalpha():\n",
    "        removed_word_list.append(word)\n",
    "        \n",
    "        \n",
    "word_dict = {} # 重複回数をカウント\n",
    "for word in removed_word_list:\n",
    "    if not word in word_dict:\n",
    "        word_dict[word] = 1\n",
    "    else:\n",
    "        word_dict[word] += 1\n",
    "                \n",
    "\n",
    "sorted_dict = sorted(word_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "# 品詞の取得\n",
    "pos = nltk.pos_tag([pair[0] for pair in sorted_dict])\n",
    "\n",
    "print(len(pos))\n",
    "# 欲しい品詞のポジションを取得\n",
    "p = []\n",
    "for i, pair in enumerate(pos):\n",
    "    po = pair[1]\n",
    "    if any(x in po for x in [\"FW\", \"JJ\", \"LS\", \"MD\", \"NN\", \"RB\", \"RP\", \"VB\"]):\n",
    "        p.append(i)\n",
    "\n",
    "sorted_dict = np.array(sorted_dict)[p]\n",
    "pos = np.array(pos)[p]\n",
    "\n",
    "print(len(p))\n",
    "print(sorted_dict.shape)\n",
    "print(pos.shape)\n",
    "print((pos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英日訳 1秒間隔で英日訳を取得\n",
    "### 単語数が少ない場合は，sleepを消してもよい．\n",
    "### 単語数が多く，sleepが短いと，接続がキャンセルされる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "translator = GoogleTranslator(sourse='en', target='ja')\n",
    "\n",
    "engs = []\n",
    "for i, word in tqdm(enumerate(sorted_dict)):\n",
    "    translated = translator.translate(word[0])\n",
    "    engs.append(translated)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(sorted_dict[i][1], sorted_dict[i][0], pos[i][0], pos[i][1], translated))\n",
    "    sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT: save_fileに保存先パスを記述！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = os.path.splitext(pdf_file)[0] + \"_word_list\" + \".csv\"\n",
    "\n",
    "with open(save_file, \"w\", encoding=\"utf-8_sig\") as f:\n",
    "    f.write(\"出現回数,\" + \"英語,\" + \"品詞,\" + \"日訳\" + \"\\n\")\n",
    "    for i, tup in tqdm(enumerate(sorted_dict)):\n",
    "        f.write(\"{},{},{},{}\\n\".format(tup[1], tup[0], pos[i][1], engs[i]))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
